{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes taken while learning Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will use this course as guide:  \n",
    "-  http://web.stanford.edu/class/cs20si/syllabus.html \n",
    "#### More info: \n",
    "-  https://github.com/chiphuyen/stanford-tensorflow-tutorials\n",
    "-  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensoflow Operations\n",
    "+  Constants\n",
    "+  Variables\n",
    "+  Placeholders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variables with tf.Variable\n",
    "s = tf.Variable(2, name=\"scalar\")   \n",
    "m = tf.Variable([[0, 1], [2, 3]], name=\"matrix\")   \n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "\n",
    "# create variables with tf.get_variable (this is better)\n",
    "s = tf.get_variable(\"scalar\", initializer=tf.constant(2))   \n",
    "m = tf.get_variable(\"matrix\", initializer=tf.constant([[0, 1], [2, 3]]))  \n",
    "W = tf.get_variable(\"big_matrix\", shape=(784, 10), initializer=tf.zeros_initializer())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we define the initializer but we dont really initialize its value. So we need to call the op when running the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The easiest way is initializing all variables at once:\n",
    "with tf.Session() as sess:\n",
    "\tsess.run(tf.global_variables_initializer())\n",
    "\n",
    "#Initialize only a subset of variables:\n",
    "with tf.Session() as sess:\n",
    "\tsess.run(tf.variables_initializer([a, b]))\n",
    "\n",
    "#Initialize a single variable\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "with tf.Session() as sess:\n",
    "\tsess.run(W.initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eval() op works like running session.run on the variable you pass, it evaluates the value of that node in the graph  \n",
    "#print(W.eval()) ---------> # Similar to print(sess.run(W))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.Variable.assign() op:  \n",
    "-  assigns a value to a variable\n",
    "-  You don’t need to initialize variable because assign_op does it for you. In fact, initializer op is the assign op that assigns the variable’s initial value to the variable itself.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(10)\n",
    "W.assign(100)\n",
    "with tf.Session() as sess:\n",
    "\tsess.run(W.initializer)\n",
    "\tprint(W.eval()) \t\t\t\t# >> 10\n",
    "\n",
    "--------\n",
    "\n",
    "W = tf.Variable(10)\n",
    "assign_op = W.assign(100)\n",
    "with tf.Session() as sess:\n",
    "sess.run(W.initializer)\n",
    "sess.run(assign_op)\n",
    "print(W.eval()) \t\t\t\t# >> 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control dependencies in graph:  \n",
    "How to specify order of execution when we have 2 or more independent variables? We use tf.Graph.control_dependencies(control_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines which ops should be run first\n",
    "# your graph g have 5 ops: a, b, c, d, e\n",
    "g = tf.get_default_graph()\n",
    "with g.control_dependencies([a, b, c]):\n",
    "\t# 'd' and 'e' will only run after 'a', 'b', and 'c' have executed.\n",
    "\td = ...\n",
    "\te = …\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholders:  \n",
    "-  We use them to supply data to our models, assembling the graph first without knowing the values needed for computation\n",
    "-  tf.placeholder(dtype, shape=None, name=None)\n",
    "\n",
    "How do we supply data to these placeholders?  \n",
    "- We can use a dictionary where the placeholder object is the key and the value is the data we need to pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a placeholder for a vector of 3 elements, type tf.float32\n",
    "a = tf.placeholder(tf.float32, shape=[3])\n",
    "\n",
    "b = tf.constant([5, 5, 5], tf.float32)\n",
    "\n",
    "# use the placeholder as you would a constant or a variable\n",
    "c = a + b  # short for tf.add(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\tprint(sess.run(c, feed_dict={a: [1, 2, 3]})) \t# the tensor a is the key, not the string ‘a’\n",
    "\n",
    "# >> [6, 7, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important note: shape=None means that tensor of any shape will be accepted as value for placeholder. shape=None is easy to construct graphs, but nightmarish for debugging.  \n",
    "shape=None also breaks all following shape inference, which makes many ops not work because they expect certain rank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to feed multiple data points, we need to do it one at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "\tfor a_value in list_of_values_for_a:\n",
    "\tprint(sess.run(c, {a: a_value}))\n",
    "    \n",
    "# How to know when can I feed data into a tensor, is this tensor a ph?\n",
    "tf.Graph.is_feedable(tensor) \n",
    "# True if and only if tensor is feedable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extremely helpful for testing: Feed in dummy values to test parts of a large graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can feed values to ops such as add \n",
    "# create operations, tensors, etc (using the default graph)\n",
    "a = tf.add(2, 5)\n",
    "b = tf.multiply(a, 3)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\t# compute the value of b given a is 15\n",
    "\tsess.run(b, feed_dict={a: 15}) \t\t\t\t# >> 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lazy Loading (Defer creating/initializing an object until it is needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normal loading\n",
    "x = tf.Variable(10, name='x')\n",
    "y = tf.Variable(20, name='y')\n",
    "z = tf.add(x, y) \t\t# create the node before executing the graph\n",
    "\n",
    "writer = tf.summary.FileWriter('./graphs/normal_loading', tf.get_default_graph())\n",
    "with tf.Session() as sess:\n",
    "\tsess.run(tf.global_variables_initializer())\n",
    "\tfor _ in range(10):\n",
    "\t\tsess.run(z)\n",
    "writer.close()\n",
    "#############################\n",
    "#Lazy loading\n",
    "x = tf.Variable(10, name='x')\n",
    "y = tf.Variable(20, name='y')\n",
    "\n",
    "writer = tf.summary.FileWriter('./graphs/normal_loading', tf.get_default_graph())\n",
    "with tf.Session() as sess:\n",
    "\tsess.run(tf.global_variables_initializer())\n",
    "\tfor _ in range(10):\n",
    "\t\tsess.run(tf.add(x, y)) # someone decides to be clever to save one line of code\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both give the same results, but whats the problem?  \n",
    "let's execute tf.get_default_graph().as_graph_def()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normal loading\n",
    "node {\n",
    "  name: \"Add\"\n",
    "  op: \"Add\"\n",
    "  input: \"x/read\"\n",
    "  input: \"y/read\"             #Node “Add” added once to the graph definition\n",
    "  attr {\n",
    "    key: \"T\"\n",
    "    value {\n",
    "      type: DT_INT32\n",
    "    }\n",
    "  }\n",
    "}\n",
    "#############################\n",
    "#Lazy loading                  Node “Add” added 10 times to the graph definition, Or as many times as you want to compute z\n",
    "node {\n",
    "  name: \"Add_1\"\n",
    "  op: \"Add\"\n",
    "  ...\n",
    "  }\n",
    "...\n",
    "node {\n",
    "  name: \"Add_10\"\n",
    "  op: \"Add\"\n",
    "  ...\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you compute an op thousands of times, your graph gets bloated, gets slow to load and expensive to pass around.\n",
    "#### Solution:   \n",
    "1  Separate definition of ops from computing/running ops  \n",
    "2  Use Python property to ensure function is also loaded once the first time it is called (https://danijar.com/structuring-your-tensorflow-models/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
